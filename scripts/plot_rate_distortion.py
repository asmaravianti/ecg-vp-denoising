"""
Generate Week 2 Rate-Distortion Plots and Visualizations

This script creates all Week 2 deliverables:
1. PRD-CR and WWPRD-CR curves
2. SNR bar charts at different CRs
3. Reconstruction overlays at CR=8 and CR=16
4. Comprehensive summary figure

Usage:
    python -m scripts.plot_rate_distortion --results_file outputs/week2/cr_sweep_results.json --output_dir outputs/week2/plots

Author: Person B
Date: October 2025
"""

import argparse
import json
import numpy as np
import torch
from pathlib import Path
from typing import Dict, Optional
import sys

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from ecgdae.visualization import (
    plot_rate_distortion_curves,
    plot_snr_bar_chart,
    plot_reconstruction_overlay,
    plot_multiple_cr_comparison,
    create_week2_summary_figure
)
from ecgdae.models import ConvAutoEncoder
from ecgdae.data import MITBIHDataset, NSTDBNoiseMixer, WindowingConfig
from ecgdae.metrics import compute_prd, compute_wwprd, compute_derivative_weights
from rich.console import Console
from rich.progress import track

console = Console()


def load_results(results_file: str) -> Dict:
    """
    Load CR sweep results from JSON file (generated by Person A).

    Args:
        results_file: Path to JSON file with format:
                     {CR: {'PRD': float, 'WWPRD': float, 'SNR_improvement': float}}

    Returns:
        Dictionary of results by CR
    """
    with open(results_file, 'r') as f:
        results = json.load(f)

    # Convert string keys to integers
    results_int = {int(k): v for k, v in results.items()}
    return results_int


def generate_mock_results() -> Dict:
    """
    Generate mock CR sweep results for testing when Person A's data isn't ready.

    This simulates realistic ECG compression results:
    - Higher CR → worse quality (higher PRD/WWPRD)
    - But still maintains reasonable SNR improvement

    Returns:
        Mock results dictionary
    """
    console.print("[yellow]⚠ No results file provided. Generating mock data for testing...[/yellow]")

    # Realistic values based on ECG compression literature
    mock_results = {
        4: {
            'PRD': 35.2,
            'PRD_std': 8.5,
            'WWPRD': 30.1,
            'WWPRD_std': 7.8,
            'SNR_in': 6.0,
            'SNR_out': 11.2,
            'SNR_improvement': 5.2,
            'latent_dim': 16,
            'quantization_bits': 8
        },
        8: {
            'PRD': 28.5,
            'PRD_std': 7.2,
            'WWPRD': 24.3,
            'WWPRD_std': 6.5,
            'SNR_in': 6.0,
            'SNR_out': 12.1,
            'SNR_improvement': 6.1,
            'latent_dim': 24,
            'quantization_bits': 8
        },
        16: {
            'PRD': 22.1,
            'PRD_std': 5.8,
            'WWPRD': 18.7,
            'WWPRD_std': 5.2,
            'SNR_in': 6.0,
            'SNR_out': 13.8,
            'SNR_improvement': 7.8,
            'latent_dim': 32,
            'quantization_bits': 8
        },
        32: {
            'PRD': 18.3,
            'PRD_std': 4.5,
            'WWPRD': 15.2,
            'WWPRD_std': 4.1,
            'SNR_in': 6.0,
            'SNR_out': 15.5,
            'SNR_improvement': 9.5,
            'latent_dim': 48,
            'quantization_bits': 8
        }
    }

    return mock_results


def generate_sample_signals(
    model_path: str,
    config_path: Optional[str] = None,
    num_samples: int = 5
) -> Dict:
    """
    Generate sample ECG signals for overlay plots.

    Loads trained model and generates reconstructions for visualization.

    Args:
        model_path: Path to trained model checkpoint
        config_path: Optional path to config JSON (for model architecture)
        num_samples: Number of samples to generate

    Returns:
        Dictionary with clean, noisy, and reconstructed signals
    """
    console.print(f"[cyan]Loading model from {model_path}...[/cyan]")

    # Load model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Try to load config if provided
    if config_path and Path(config_path).exists():
        with open(config_path, 'r') as f:
            config = json.load(f)

        if config.get('model_type') == 'residual':
            from ecgdae.models import ResidualAutoEncoder
            model = ResidualAutoEncoder(
                in_channels=1,
                hidden_dims=tuple(config.get('hidden_dims', [32, 64, 128])),
                latent_dim=config.get('latent_dim', 32),
            )
        else:
            model = ConvAutoEncoder(
                in_channels=1,
                hidden_dims=tuple(config.get('hidden_dims', [32, 64, 128])),
                latent_dim=config.get('latent_dim', 32),
            )
    else:
        # Default architecture
        model = ConvAutoEncoder(
            in_channels=1,
            hidden_dims=(32, 64, 128),
            latent_dim=32,
            kernel_size=9
        )

    # Load checkpoint (weights_only=False for PyTorch 2.6+ compatibility)
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)

    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)

    model.to(device)
    model.eval()

    # Load test data
    console.print("[cyan]Loading MIT-BIH test data...[/cyan]")

    # Use the test dataset approach instead of direct record loading
    from ecgdae.data import MITBIHDataset, MITBIHLoader, WindowingConfig
    import torch.utils.data as data_utils

    # Create windowing config
    window_config = WindowingConfig(
        sample_rate=360,
        window_seconds=2.0,
        step_seconds=2.0,
    )

    # Create noise mixer
    try:
        nstdb = NSTDBNoiseMixer(data_dir="./data/nstdb")
        noise_mixer = nstdb.create_mixer(
            target_snr_db=10.0,
            noise_type='muscle_artifact',
        )
    except:
        # Fallback to Gaussian noise
        from ecgdae.data import gaussian_snr_mixer
        noise_mixer = gaussian_snr_mixer(10.0)

    # Use test records (different from training)
    test_records = ['111', '112', '113']

    # Create dataset
    try:
        test_dataset = MITBIHDataset(
            records=test_records,
            config=window_config,
            noise_mixer=noise_mixer,
            data_dir="./data/mitbih",
            channel=0,
            normalize=True,
        )

        # Create a small dataloader
        test_loader = data_utils.DataLoader(
            test_dataset,
            batch_size=1,
            shuffle=False,
            num_workers=0,
        )

        signals_dict = {'clean': [], 'noisy': [], 'reconstructed': []}

        with torch.no_grad():
            for i, (noisy_batch, clean_batch) in enumerate(test_loader):
                if i >= num_samples:
                    break

                noisy_batch = noisy_batch.to(device)
                clean_batch = clean_batch.to(device)

                # Reconstruct
                recon_batch = model(noisy_batch)

                # Extract single sample
                clean = clean_batch[0, 0].cpu().numpy()
                noisy = noisy_batch[0, 0].cpu().numpy()
                recon = recon_batch[0, 0].cpu().numpy()

                signals_dict['clean'].append(clean)
                signals_dict['noisy'].append(noisy)
                signals_dict['reconstructed'].append(recon)

        if len(signals_dict['clean']) == 0:
            raise ValueError("No signals generated from dataset")

    except Exception as e:
        console.print(f"[yellow]Warning: Could not generate signals from dataset: {e}[/yellow]")
        console.print("[yellow]Falling back to mock signals...[/yellow]")
        raise  # Re-raise to trigger mock data fallback

    return signals_dict


def generate_mock_signals() -> Dict:
    """
    Generate synthetic ECG signals for testing when model isn't available.

    Creates realistic-looking ECG waveforms using sum of sinusoids.
    """
    console.print("[yellow]⚠ No model provided. Generating synthetic ECG signals...[/yellow]")

    def synthetic_ecg(length: int = 512, fs: int = 360) -> np.ndarray:
        """Generate one synthetic ECG beat"""
        t = np.arange(length) / fs

        # P wave (small bump)
        p_wave = 0.15 * np.exp(-((t - 0.15) ** 2) / 0.001)

        # QRS complex (sharp spike)
        qrs = 1.0 * np.exp(-((t - 0.3) ** 2) / 0.0001)

        # T wave (medium bump)
        t_wave = 0.3 * np.exp(-((t - 0.5) ** 2) / 0.002)

        # Combine
        ecg = p_wave + qrs + t_wave

        # Normalize
        ecg = (ecg - np.mean(ecg)) / (np.std(ecg) + 1e-8)

        return ecg

    num_samples = 3
    signals_dict = {'clean': [], 'noisy': [], 'reconstructed': []}

    for i in range(num_samples):
        clean = synthetic_ecg()

        # Add Gaussian noise (SNR = 10 dB)
        noise_power = np.mean(clean ** 2) / (10 ** (10.0 / 10))
        noise = np.random.normal(0, np.sqrt(noise_power), len(clean))
        noisy = clean + noise

        # Simulate reconstruction (add small error)
        reconstruction_error = np.random.normal(0, 0.1, len(clean))
        reconstructed = clean + reconstruction_error * 0.3

        signals_dict['clean'].append(clean)
        signals_dict['noisy'].append(noisy)
        signals_dict['reconstructed'].append(reconstructed)

    return signals_dict


def main():
    parser = argparse.ArgumentParser(
        description="Generate Week 2 rate-distortion plots and visualizations"
    )

    parser.add_argument(
        '--results_file',
        type=str,
        default=None,
        help='Path to CR sweep results JSON (from Person A)'
    )

    parser.add_argument(
        '--model_path',
        type=str,
        default='outputs/week1_presentation/best_model.pth',
        help='Path to trained model for generating reconstructions'
    )

    parser.add_argument(
        '--config_path',
        type=str,
        default=None,
        help='Path to training config JSON (for model architecture)'
    )

    parser.add_argument(
        '--output_dir',
        type=str,
        default='outputs/week2_plots',
        help='Directory to save plots'
    )

    parser.add_argument(
        '--use_mock_data',
        action='store_true',
        help='Use mock data for testing (when Person A data not ready)'
    )

    args = parser.parse_args()

    # Create output directory
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    console.print("\n[bold cyan]═══ Week 2: Rate-Distortion Visualization ═══[/bold cyan]\n")

    # === STEP 1: Load or generate CR sweep results ===
    console.print("[bold]Step 1: Loading CR sweep results...[/bold]")

    if args.results_file and Path(args.results_file).exists() and not args.use_mock_data:
        results = load_results(args.results_file)
        console.print(f"[green]✓ Loaded results from {args.results_file}[/green]")
    else:
        results = generate_mock_results()
        console.print("[yellow]✓ Using mock data[/yellow]")

    console.print(f"  Found CRs: {sorted(results.keys())}")

    # === STEP 2: Generate rate-distortion curves ===
    console.print("\n[bold]Step 2: Generating rate-distortion curves...[/bold]")

    rd_path = output_dir / 'rate_distortion_curves.png'
    plot_rate_distortion_curves(
        results,
        str(rd_path),
        title="ECG Compression: Rate-Distortion Trade-off"
    )

    # === STEP 3: Generate SNR bar charts ===
    console.print("\n[bold]Step 3: Generating SNR bar charts...[/bold]")

    snr_path = output_dir / 'snr_bar_chart.png'
    plot_snr_bar_chart(
        results,
        str(snr_path),
        title="SNR Improvement at Different Compression Ratios"
    )

    # === STEP 4: Generate reconstruction overlays ===
    console.print("\n[bold]Step 4: Generating reconstruction overlays...[/bold]")

    # Try to use real model, fall back to mock data
    if Path(args.model_path).exists() and not args.use_mock_data:
        try:
            # Try to find config path automatically if not provided
            config_path = args.config_path
            if not config_path:
                # Look for config in same directory as model
                model_dir = Path(args.model_path).parent
                config_path = model_dir / 'config.json'
                if not config_path.exists():
                    config_path = None

            signals_dict = generate_sample_signals(
                args.model_path,
                config_path=config_path,
                num_samples=3
            )
            using_real_data = True
        except Exception as e:
            console.print(f"[yellow]Warning: Could not generate real signals: {e}[/yellow]")
            console.print(f"[yellow]Falling back to mock data for visualization...[/yellow]")
            signals_dict = generate_mock_signals()
            using_real_data = False
    else:
        signals_dict = generate_mock_signals()
        using_real_data = False

    # Generate individual overlays for CR=8 and CR=16
    if len(signals_dict['clean']) > 0:
        for cr in [8, 16]:
            if cr in results:
                console.print(f"  Creating overlay for CR={cr}...")

                # Use first sample
                clean = signals_dict['clean'][0]
                noisy = signals_dict['noisy'][0]
                recon = signals_dict['reconstructed'][0]

                # Compute actual metrics for this sample
                metrics = {
                    'PRD': compute_prd(clean, recon),
                    'WWPRD': compute_wwprd(clean, recon),
                    'SNR_improvement': results[cr]['SNR_improvement']  # Use average from results
                }

                overlay_path = output_dir / f'reconstruction_overlay_cr{cr}.png'
                plot_reconstruction_overlay(
                    clean, noisy, recon,
                    metrics,
                    str(overlay_path),
                    compression_ratio=cr
                )

    # Generate multi-CR comparison
    if len(signals_dict['clean']) > 0:
        console.print("  Creating multi-CR comparison...")

        comparison_signals = {}
        comparison_metrics = {}

        for idx, cr in enumerate([8, 16]):
            if cr in results and idx < len(signals_dict['clean']):
                comparison_signals[cr] = {
                    'clean': signals_dict['clean'][min(idx, len(signals_dict['clean'])-1)],
                    'noisy': signals_dict['noisy'][min(idx, len(signals_dict['noisy'])-1)],
                    'reconstructed': signals_dict['reconstructed'][min(idx, len(signals_dict['reconstructed'])-1)]
                }

                comparison_metrics[cr] = {
                    'PRD': results[cr]['PRD'],
                    'WWPRD': results[cr]['WWPRD'],
                    'SNR_improvement': results[cr]['SNR_improvement']
                }

        if comparison_signals:
            multi_path = output_dir / 'multi_cr_comparison.png'
            plot_multiple_cr_comparison(
                comparison_signals,
                comparison_metrics,
                str(multi_path)
            )

    # === STEP 5: Generate comprehensive summary figure ===
    console.print("\n[bold]Step 5: Generating Week 2 summary figure...[/bold]")

    summary_path = output_dir / 'week2_summary.png'
    create_week2_summary_figure(results, str(summary_path))

    # === STEP 6: Create results summary JSON ===
    console.print("\n[bold]Step 6: Saving summary JSON...[/bold]")

    summary_json = {
        'compression_ratios': sorted(results.keys()),
        'metrics_by_cr': results,
        'best_cr_by_quality': {
            'PRD': min(results.keys(), key=lambda cr: results[cr]['PRD']),
            'WWPRD': min(results.keys(), key=lambda cr: results[cr]['WWPRD']),
            'SNR': max(results.keys(), key=lambda cr: results[cr]['SNR_improvement'])
        },
        'data_source': 'real' if (using_real_data and not args.use_mock_data) else 'mock',
        'results_source': 'real' if (args.results_file and Path(args.results_file).exists() and not args.use_mock_data) else 'mock'
    }

    summary_json_path = output_dir / 'week2_visualization_summary.json'
    with open(summary_json_path, 'w') as f:
        json.dump(summary_json, f, indent=2)

    console.print(f"[green]✓ Saved summary to {summary_json_path}[/green]")

    # === Final Summary ===
    console.print("\n[bold green]═══ Week 2 Plots Generated Successfully! ═══[/bold green]\n")
    console.print(f"[cyan]Output directory:[/cyan] {output_dir}")
    console.print("\n[bold]Generated files:[/bold]")
    console.print(f"  1. {rd_path.name} - Rate-distortion curves (PRD-CR, WWPRD-CR)")
    console.print(f"  2. {snr_path.name} - SNR bar charts")
    console.print(f"  3. reconstruction_overlay_cr8.png - Overlay at CR=8")
    console.print(f"  4. reconstruction_overlay_cr16.png - Overlay at CR=16")
    console.print(f"  5. multi_cr_comparison.png - Side-by-side comparison")
    console.print(f"  6. {summary_path.name} - Comprehensive summary figure")
    console.print(f"  7. {summary_json_path.name} - JSON summary")

    console.print("\n[bold]Next steps:[/bold]")
    console.print("  • Share plots with Person A to verify against their metrics")
    console.print("  • Include these plots in Week 2 presentation")
    console.print("  • Prepare to explain rate-distortion trade-offs to professor")


if __name__ == "__main__":
    main()

